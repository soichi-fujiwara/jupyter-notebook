{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modelToDB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soichi-fujiwara/jupyter-notebook/blob/master/modelToDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCMfweVZEzPd",
        "colab_type": "text"
      },
      "source": [
        "##モデルをDB化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhMbBx_ECoOl",
        "colab_type": "code",
        "outputId": "8e9fa9c8-9eb8-4970-96d3-db01ff4bd9a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRJCjIdrc3nQ",
        "colab_type": "code",
        "outputId": "24b0092b-0d74-4a62-8f40-e54a5f8d03fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import IPython\n",
        "#bz2ファイル解凍\n",
        "#!bunzip2 -k -q \"./drive/My Drive/NLP/20170201.tar.bz2\"\n",
        "\n",
        "#tarファイル解凍\n",
        "!tar -xvf \"./drive/My Drive/NLP/20170201.tar\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "entity_vector/\n",
            "entity_vector/entity_vector.model.txt\n",
            "entity_vector/entity_vector.model.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2jUrFtNeMMH",
        "colab_type": "code",
        "outputId": "a0bd7596-18c6-4981-d237-7b8175526978",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "#解凍時のみ\n",
        "model_dir = 'entity_vector/entity_vector.model.bin'\n",
        "model = KeyedVectors.load_word2vec_format(model_dir, binary=True,limit=500000)\n",
        "\n",
        "#解凍後確認\n",
        "results = model.most_similar(positive=[u'数学'])\n",
        "for result in results:\n",
        "  print(result)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "('[数学]', 0.8441122770309448)\n",
            "('物理学', 0.8005046844482422)\n",
            "('算術', 0.7927638292312622)\n",
            "('[幾何学]', 0.7776163220405579)\n",
            "('[物理学]', 0.7547159194946289)\n",
            "('[代数学]', 0.7514173984527588)\n",
            "('代数学', 0.7450574636459351)\n",
            "('[解析学]', 0.741286039352417)\n",
            "('[確率論]', 0.7390509843826294)\n",
            "('[数論]', 0.7337667942047119)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEruRmNNatxY",
        "colab_type": "code",
        "outputId": "94a7e9fa-d4a6-4ebd-d8a7-16c85bb2c1f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!pip install mecab-python3"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mecab-python3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/92/e7e7f38df8457fa40c1ca86928be5ddbe2bf341e90a35e6ada30d03ef16d/mecab_python3-0.996.2-cp36-cp36m-manylinux1_x86_64.whl (15.9MB)\n",
            "\u001b[K     |████████████████████████████████| 15.9MB 3.1MB/s \n",
            "\u001b[?25hInstalling collected packages: mecab-python3\n",
            "Successfully installed mecab-python3-0.996.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OzKgJ9slAsf",
        "colab_type": "text"
      },
      "source": [
        "##語彙-対義語候補 対応CSV作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5yIYDAfPHQu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "6fc27d86-4f9e-4ce8-f4aa-9dd58d559860"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "cnt = 1\n",
        "model_vocab_list = []\n",
        "\n",
        "for words, v in model.vocab.items():\n",
        "\n",
        "  words = words.replace('_', '')\n",
        "  \n",
        "  #固有名詞用の括弧を削除\n",
        "  words = words.replace('[', '').replace(']', '')\n",
        "\n",
        "  #補足情報の_を削除\n",
        "  words = words.replace(\"_\",\"\")\n",
        "  #括弧文字を抽出\n",
        "  regex = re.compile(\".*?\\((.*?)\\)\")\n",
        "  #括弧文字をlist型で返却\n",
        "  ret_list = re.findall(regex, words)\n",
        "\n",
        "  #括弧文字がある場合は無効化\n",
        "  if len(ret_list) > 0: \n",
        "    words = words.replace(\"(\" + ret_list[0] + \")\",'')\n",
        "    model_vocab_list.append(words)\n",
        "  else:\n",
        "    model_vocab_list.append(words)\n",
        "    \n",
        "  if cnt % 50000 == 0:\n",
        "    print(cnt,\"件 完了\");\n",
        "    \n",
        "  cnt = cnt + 1\n",
        "\n",
        "#重複削除\n",
        "model_vocab_uni_list= list(set(model_vocab_list))\n",
        "  \n",
        "#保存\n",
        "df = pd.DataFrame(model_vocab_uni_list)\n",
        "df.to_csv('./drive/My Drive/NLP/model_vocab_list.csv', header=False, index=False)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 件 完了\n",
            "100000 件 完了\n",
            "150000 件 完了\n",
            "200000 件 完了\n",
            "250000 件 完了\n",
            "300000 件 完了\n",
            "350000 件 完了\n",
            "400000 件 完了\n",
            "450000 件 完了\n",
            "500000 件 完了\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRvxKV48SLUM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e3cddc4a-23e8-4d9f-ae35-91d2c8630f7e"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_dir = './drive/My Drive/NLP/model_vocab_list.csv'\n",
        "df = pd.read_csv(csv_dir,names=['words'])\n",
        "df = df.sort_values('words', ascending=True)\n",
        "\n",
        "print(df.count())\n",
        "print(df[df[\"words\"]==\"ゆず\"])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "words    425495\n",
            "dtype: int64\n",
            "       words\n",
            "360410    ゆず\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdwy6HUsTA_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import MeCab\n",
        "#括弧記号無効化\n",
        "import lib_delete_brackets\n",
        "\n",
        "def search_similar_texts(p_words):\n",
        "  pass\n",
        "\n",
        "def wordRevChange(words,gyaku,inherent_words,model,tokenizer):\n",
        "\n",
        "  word_cng_list = []\n",
        "\n",
        "  #**************************************************************************\n",
        "  #そのまま対義化\n",
        "  #**************************************************************************\n",
        "  asitis_cng_words1 = ''\n",
        "  asitis_cng_words2 = ''\n",
        "  try:\n",
        "    for i in range(2):\n",
        "      rvs_wd = model.most_similar(positive=[inherent_words,gyaku])[i][0]\n",
        "      if inherent_words.replace('[',\"\").replace(']',\"\") != rvs_wd.replace('[',\"\").replace(']',\"\"):\n",
        "        asitis_cng_words1 = model.most_similar(positive=[inherent_words,gyaku])[i][0]\n",
        "        asitis_cng_words2 = model.most_similar(positive=[inherent_words,gyaku])[i+1][0]\n",
        "        break\n",
        "      else:\n",
        "        asitis_cng_words = words\n",
        "  except KeyError as error:\n",
        "    #辞書に登録の無い単語の場合\n",
        "    search_similar_texts(inherent_words)\n",
        "\n",
        "  #**************************************************************************\n",
        "  #形態素分析後に対義化\n",
        "  #**************************************************************************\n",
        "  node = tokenizer.parseToNode(words)\n",
        "\n",
        "  while node:\n",
        "    cut_wd = node.surface\n",
        "\n",
        "    if node.feature.split(\",\")[0] == u\"名詞\":\n",
        "      try:\n",
        "        rvs_wd_list = model.most_similar(positive=[cut_wd,gyaku])\n",
        "        for i in range(2):\n",
        "          rvs_wd = rvs_wd_list[i][0]\n",
        "          if cut_wd != rvs_wd.replace('[',\"\").replace(']',\"\"):\n",
        "            #◆結合\n",
        "            word_cng_list.append(rvs_wd.replace('[',\"\").replace(']',\"\"))\n",
        "            break\n",
        "      except KeyError as error:\n",
        "        #辞書に登録の無い単語の場合\n",
        "        search_similar_texts(cut_wd)\n",
        "\n",
        "    elif node.feature.split(\",\")[0] == u\"形容詞\":\n",
        "      cut_wd = node.feature.split(\",\")[6]\n",
        "\n",
        "      try:\n",
        "        rvs_wd_list = model.most_similar(positive=[cut_wd,gyaku])\n",
        "        for i in range(2):\n",
        "          rvs_wd = rvs_wd_list[i][0]\n",
        "          if cut_wd != rvs_wd.replace('[',\"\").replace(']',\"\"):\n",
        "            #◆結合\n",
        "            word_cng_list.append(rvs_wd.replace('[',\"\").replace(']',\"\"))\n",
        "            break\n",
        "      except KeyError as error:\n",
        "        #辞書に登録の無い単語の場合\n",
        "        search_similar_texts(cut_wd)\n",
        "\n",
        "    elif node.feature.split(\",\")[0] == u\"動詞\":\n",
        "      cu_wd = node.feature.split(\",\")[6]\n",
        "\n",
        "      try:\n",
        "        rvs_wd_list = model.most_similar(positive=[cut_wd,gyaku])\n",
        "        for i in range(2):\n",
        "          rvs_wd = rvs_wd_list[i][0]\n",
        "          if cut_wd != rvs_wd.replace('[',\"\").replace(']',\"\"):\n",
        "            #◆結合\n",
        "            word_cng_list.append(rvs_wd.replace('[',\"\").replace(']',\"\"))\n",
        "            break\n",
        "      except KeyError as error:\n",
        "        #辞書に登録の無い単語の場合\n",
        "        search_similar_texts(cut_wd)\n",
        "\n",
        "    else:\n",
        "      #◆結合\n",
        "      word_cng_list.append(cut_wd.replace('[',\"\").replace(']',\"\"))\n",
        "\n",
        "    node = node.next\n",
        "\n",
        "  asitis_cng_words1 = asitis_cng_words1.replace('[',\"\").replace(']',\"\").replace('_',\"\")\n",
        "  asitis_cng_words2 = asitis_cng_words2.replace('[',\"\").replace(']',\"\").replace('_',\"\")\n",
        "\n",
        "  result_list = []\n",
        "\n",
        "  result_list.append(words)\n",
        "  #result_list.append(lib_delete_brackets.delete_brackets(asitis_cng_words1))\n",
        "  #result_list.append(lib_delete_brackets.delete_brackets(asitis_cng_words2))\n",
        "  result_list.append(asitis_cng_words1)\n",
        "  result_list.append(asitis_cng_words2)\n",
        "  result_list.append(''.join(word_cng_list))\n",
        "\n",
        "  return result_list\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQGM66ine9J3",
        "colab_type": "code",
        "outputId": "1eab5dea-bb9e-45c8-b4a7-f3259bf7c902",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import MeCab\n",
        "#対義語生成\n",
        "#import lib_wordRevChange as lw\n",
        "\n",
        "tokenizer = MeCab.Tagger(\"-Ochasen\")\n",
        "\n",
        "cnt = 1\n",
        "save_list = []\n",
        "\n",
        "#列[words]をnumpyに変換\n",
        "val = df.words.values\n",
        "\n",
        "for idx in range(df.shape[0]):\n",
        "\n",
        "  words = str(val[idx])\n",
        "  \n",
        "  if len(words) <= 10:\n",
        "    if words.isdecimal() is False:\n",
        "      if '・' not in words:\n",
        "        gyaku = u\"逆\"\n",
        "        inherent_words = '[' + words + ']'  \n",
        "        rev_list = wordRevChange(words,gyaku,inherent_words,model,tokenizer)\n",
        "        save_list.append(rev_list)\n",
        "\n",
        "  if cnt % 1000 == 0:\n",
        "    print(cnt,\"件 終了\")\n",
        "    #Gドライブ再マウント\n",
        "    drive.mount('/content/drive')  \n",
        "    #保存\n",
        "    df2 = pd.DataFrame(save_list)\n",
        "    df2.to_csv('./drive/My Drive/NLP/modelToCsv.csv', header=False, index=False)\n",
        "    \n",
        "  cnt = cnt + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93NfdGafVlHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rt = model.most_similar(positive=[\"[世界に一つだけの花]\"])\n",
        "rt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOhrO5yHTa_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}