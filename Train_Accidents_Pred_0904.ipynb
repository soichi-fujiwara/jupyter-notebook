{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_Accidents_Pred_0904.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soichi-fujiwara/jupyter-notebook/blob/master/Train_Accidents_Pred_0904.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCMkQx8VAs2r",
        "colab_type": "text"
      },
      "source": [
        "##乗降人数を20段階に分類"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2LtPzblnoMl",
        "colab_type": "code",
        "outputId": "7bcf2b8e-5db7-4f84-9a04-a72146ea5022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BRnbysUNIUP",
        "colab_type": "code",
        "outputId": "240da86a-9cf6-40b0-8abf-17fb8823a57f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_ac = pd.read_csv(\"./drive/My Drive/TrainAccident/Accident_list.csv\")\n",
        "\n",
        "#鉄道会社の人身事故発生順にソート\n",
        "df_line = df_ac[\"line\"].value_counts().reset_index()\n",
        "\n",
        "#SeriseをDataFrameに変換\n",
        "col_name = [\"line\",\"count\"]\n",
        "df_line = pd.DataFrame(df_line)\n",
        "\n",
        "df_line.columns = col_name\n",
        "df_line.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>line</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>東武東上線</td>\n",
              "      <td>291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>山陽本線_(JR西日本)</td>\n",
              "      <td>263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>京浜東北線</td>\n",
              "      <td>245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>中央快速線</td>\n",
              "      <td>244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>東海道線_(JR東海)</td>\n",
              "      <td>244</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           line  count\n",
              "0         東武東上線    291\n",
              "1  山陽本線_(JR西日本)    263\n",
              "2         京浜東北線    245\n",
              "3         中央快速線    244\n",
              "4   東海道線_(JR東海)    244"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM5ZTERQx19M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#件数は削除\n",
        "df_line = df_line.drop(\"count\",axis=1)\n",
        "df_line\n",
        "\n",
        "#CSVに出力\n",
        "df_line.to_csv(\"./drive/My Drive/TrainAccident/line_List_Candidate.csv\", encoding = 'utf-8',index=False,header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZoYVrjllY1F",
        "colab_type": "code",
        "outputId": "27ad8ca8-4cbf-46e5-d308-ef66d7b14cd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import itertools\n",
        "\n",
        "kanto_line = pd.read_table('./drive/My Drive/TrainAccident/kanto_line.txt', header=None)\n",
        "\n",
        "#dataframeをlist化\n",
        "kanto_line_list = kanto_line.values.tolist()\n",
        "#2次元listから1次元listへ\n",
        "kanto_line_list = list(itertools.chain.from_iterable(kanto_line_list))\n",
        "\n",
        "print(kanto_line_list)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['東武東上線', '京浜東北線', '中央快速線', '常磐線', '小田急小田原線', '西武新宿線', '宇都宮線', '京王線', '京急本線', '西武池袋線', '東武伊勢崎線', '東海道線_(JR東日本)', '高崎線', '中央・総武緩行線', '東急田園都市線', '山手線', '東北本線', '近鉄大阪線', '京成本線', '横浜線', '横須賀線', '総武快速線', '南武線', '埼京線', '相鉄本線', '東武野田線', '東急東横線', '外房線', '新京成電鉄新京成線', '中央本線_(JR東日本)', '小田急江ノ島線', '武蔵野線', '総武本線', '都電荒川線', '東京メトロ東西線', '青梅線', '関東鉄道常総線', '成田線', '根岸線', '京王井の頭線', '都営地下鉄新宿線', '京葉線', '秩父鉄道秩父本線', '東急大井町線', '東京メトロ千代田線', '八高線', '東急池上線', '京王相模原線', '川越線', '東京メトロ日比谷線', '西武拝島線', '京成押上線', '相模線', '都営地下鉄浅草線', '江ノ島電鉄線', '東武スカイツリーライン', '東京メトロ半蔵門線', '東武アーバンパークライン', '都営地下鉄大江戸線', '東葉高速鉄道東葉高速線', '東京メトロ銀座線', '小田急多摩線', '横浜高速鉄道みなとみらい線', 'JR東西線', '首都圏新都市鉄道つくばエクスプレス', '京急空港線', '相鉄いずみ野線', '東京メトロ有楽町線', '東京臨海高速鉄道りんかい線', '鶴見線', '東京モノレール羽田空港線', '東武亀戸線', '京葉臨海鉄道臨海本線', '京王新線', '西武秩父線', '埼玉高速鉄道線', '横浜市営地下鉄ブルーライン']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlDxCe9goErC",
        "colab_type": "code",
        "outputId": "5057b338-8c54-44d1-eddc-e0b492087699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#関東(首都圏)に影響を与えそうな路線のデータのみ抽出\n",
        "new_data = df_ac[df_ac['line'].isin(kanto_line_list)]\n",
        "new_data = new_data.reset_index()\n",
        "\n",
        "#不要な項目を削除\n",
        "new_data = new_data.drop(\"index\",axis=1)\n",
        "\n",
        "new_data.head(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>time</th>\n",
              "      <th>yobi</th>\n",
              "      <th>line</th>\n",
              "      <th>from_st</th>\n",
              "      <th>to_st</th>\n",
              "      <th>st</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019/08/10</td>\n",
              "      <td>20:08</td>\n",
              "      <td>5</td>\n",
              "      <td>八高線</td>\n",
              "      <td>拝島駅</td>\n",
              "      <td>東福生駅</td>\n",
              "      <td>拝島駅</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019/08/09</td>\n",
              "      <td>22:39</td>\n",
              "      <td>4</td>\n",
              "      <td>東急東横線</td>\n",
              "      <td>学芸大学駅</td>\n",
              "      <td>学芸大学駅</td>\n",
              "      <td>学芸大学駅</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019/08/07</td>\n",
              "      <td>18:00</td>\n",
              "      <td>2</td>\n",
              "      <td>宇都宮線</td>\n",
              "      <td>東大宮駅</td>\n",
              "      <td>蓮田駅</td>\n",
              "      <td>東大宮駅</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019/08/06</td>\n",
              "      <td>11:54</td>\n",
              "      <td>1</td>\n",
              "      <td>総武本線</td>\n",
              "      <td>八街駅</td>\n",
              "      <td>日向駅</td>\n",
              "      <td>八街駅</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019/08/05</td>\n",
              "      <td>12:18</td>\n",
              "      <td>0</td>\n",
              "      <td>東急大井町線</td>\n",
              "      <td>自由が丘駅</td>\n",
              "      <td>九品仏駅</td>\n",
              "      <td>自由が丘駅</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date   time  yobi    line from_st  to_st     st\n",
              "0  2019/08/10  20:08     5     八高線     拝島駅   東福生駅    拝島駅\n",
              "1  2019/08/09  22:39     4   東急東横線   学芸大学駅  学芸大学駅  学芸大学駅\n",
              "2  2019/08/07  18:00     2    宇都宮線    東大宮駅    蓮田駅   東大宮駅\n",
              "3  2019/08/06  11:54     1    総武本線     八街駅    日向駅    八街駅\n",
              "4  2019/08/05  12:18     0  東急大井町線   自由が丘駅   九品仏駅  自由が丘駅"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E9BMrcvJhiZ",
        "colab_type": "code",
        "outputId": "e102cccc-3fc4-4240-8bc7-2cd3730b213d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#乗車人数\n",
        "ninzu_df = pd.read_csv(\"./drive/My Drive/TrainAccident/TrainNinzu.csv\")\n",
        "ninzu_df['ninzu'] = ninzu_df['ninzu'].astype('float')\n",
        "ninzu_df.head()\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>st</th>\n",
              "      <th>ninzu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>JR三山木駅</td>\n",
              "      <td>1899.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>JR五位堂駅</td>\n",
              "      <td>1567.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>JR俊徳道駅</td>\n",
              "      <td>8147.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>JR小倉駅</td>\n",
              "      <td>3752.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>JR河内永和駅</td>\n",
              "      <td>12844.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        st    ninzu\n",
              "0   JR三山木駅   1899.0\n",
              "1   JR五位堂駅   1567.0\n",
              "2   JR俊徳道駅   8147.0\n",
              "3    JR小倉駅   3752.0\n",
              "4  JR河内永和駅  12844.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfnSdz67hVBZ",
        "colab_type": "code",
        "outputId": "8f60c07a-778e-4ff4-be2f-4e6445f6e35b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import date, timedelta\n",
        "import datetime\n",
        "import itertools\n",
        "\n",
        "#祝日\n",
        "holi_df = pd.read_csv(\"./drive/My Drive/TrainAccident/holiday.csv\")\n",
        "#キー結合させる為\n",
        "holi_df[\"date\"] = holi_df['date'].astype('str')\n",
        "\n",
        "#土日\n",
        "donichi_df = pd.DataFrame({\"date\": [pd.to_datetime(\"2010-01-01\") + timedelta(days=i) for i in range(3650)]},dtype=\"object\")\n",
        "donichi_df = donichi_df.assign(yobi=pd.to_datetime(donichi_df['date']).apply(lambda x: x.weekday()))\n",
        "\n",
        "donichi_df['date'] = donichi_df['date'].astype('str')\n",
        "donichi_df['date'] = donichi_df['date'].str[0:10]\n",
        "\n",
        "donichi_df = donichi_df[donichi_df['yobi'] >= 5]\n",
        "donichi_df['date'] = donichi_df['date'].str.replace('-', '/')\n",
        "donichi_list = donichi_df['date'].tolist()\n",
        "\n",
        "donichi_df.to_csv(\"./drive/My Drive/TrainAccident/donichi.csv\")\n",
        "\n",
        "print(holi_df.head())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         date  holiday_flg\n",
            "0  2010/01/01            1\n",
            "1  2010/01/11            1\n",
            "2  2010/02/11            1\n",
            "3  2010/03/21            1\n",
            "4  2010/03/22            1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3tC7j8jt4rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "from datetime import date, timedelta\n",
        "\n",
        "new_df = new_data.copy()\n",
        "\n",
        "#-------------------------------------------------------------------------------------------\n",
        "#時間帯\n",
        "#-------------------------------------------------------------------------------------------\n",
        "new_df = new_df.assign(time_category=new_df['time'])\n",
        "\n",
        "new_df.loc[(new_df['time_category'].str[0:2].isin([\"04\",\"05\"])) ,\"time_category\"] = \"morning_time\"\n",
        "new_df.loc[(new_df['time_category'].str[0:2].isin([\"06\",\"07\",\"08\",\"09\"])) ,\"time_category\"] = \"comp_time\"\n",
        "new_df.loc[(new_df['time_category'].str[0:2].isin([\"17\",\"18\",\"19\",\"20\"])) ,\"time_category\"] = \"home_time\"\n",
        "new_df.loc[(new_df['time_category'].str[0:2].isin([\"21\",\"22\",\"23\"])) ,\"time_category\"] = \"night_time\"\n",
        "new_df.loc[(new_df['time_category'].str[0:2].isin([\"00\",\"01\",\"02\",\"03\"])) ,\"time_category\"] = \"midnight_time\"\n",
        "new_df.loc[(new_df['time_category'].str[0:2].isin([\"10\",\"11\",\"12\"])) ,\"time_category\"] = \"day_am_time\"\n",
        "new_df.loc[(new_df['time_category'].str[0:2].isin([\"13\",\"14\",\"15\",\"16\"])) ,\"time_category\"] = \"day_pm_time\"\n",
        "\n",
        "dmy_df = pd.get_dummies(new_df['time_category'])\n",
        "add_df = pd.merge(new_df, dmy_df, left_index=True, right_index=True)\n",
        "add_df = add_df.drop([\"time\",\"time_category\"],axis=1)\n",
        "\n",
        "#-------------------------------------------------------------------------------------------\n",
        "#曜日\n",
        "#-------------------------------------------------------------------------------------------\n",
        "dmy_df = pd.get_dummies(add_df['yobi'],prefix='yobi')\n",
        "add_df = pd.merge(add_df, dmy_df, left_index=True, right_index=True)\n",
        "add_df = add_df.drop(\"yobi\",axis=1)\n",
        "\n",
        "#-------------------------------------------------------------------------------------------\n",
        "#祝日\n",
        "#-------------------------------------------------------------------------------------------\n",
        "add_df = pd.merge(add_df,holi_df, on='date' , how='left')#left join\n",
        "Special_holiday_list = [\"08/13\",\"08/14\",\"08/15\",\"08/16\",\"12/29\",\"12/30\",\"12/31\",\"01/02\",\"01/03\",\"01/04\"]\n",
        "\n",
        "#土日も休日扱いに\n",
        "add_df.loc[(add_df['date'].str[5:10].isin(donichi_list)) ,\"holiday_flg\"] = 1\n",
        "add_df.loc[(add_df['date'].str[5:10].isin(Special_holiday_list)) ,\"holiday_flg\"] = 1\n",
        "add_df.loc[(add_df['holiday_flg'].isnull()) ,\"holiday_flg\"] = 0\n",
        "\n",
        "#-------------------------------------------------------------------------------------------\n",
        "#休み明け\n",
        "#-------------------------------------------------------------------------------------------\n",
        "#祝日\n",
        "holi_df2 = holi_df.drop([\"holiday_flg\"],axis=1)\n",
        "#土日\n",
        "donichi_df2 = donichi_df.drop([\"yobi\"],axis=1)\n",
        "\n",
        "year_list = [\"2010\",\"2011\",\"2012\",\"2013\",\"2014\",\"2015\",\"2016\",\"2017\",\"2018\",\"2019\"]\n",
        "Special_holiday_list = [\"08/13\",\"08/14\",\"08/15\",\"08/16\",\"12/29\",\"12/30\",\"12/31\",\"01/02\",\"01/03\",\"01/04\"]\n",
        "\n",
        "holi_all_list = []\n",
        "\n",
        "for yl in year_list:\n",
        "  for sl in Special_holiday_list:\n",
        "    wk = str(yl) + \"/\" + str(sl)\n",
        "    holi_all_list.append(wk)\n",
        "\n",
        "special_holi_df = pd.DataFrame(holi_all_list,columns=[\"date\"])\n",
        "\n",
        "#全休日\n",
        "holi_all_df = pd.concat([holi_df,donichi_df,special_holi_df],axis=0)\n",
        "holi_all_df = holi_all_df[~holi_all_df.duplicated([\"date\"])].sort_values('date', ascending=True).reset_index(drop=True)\n",
        "\n",
        "holi_all_list = holi_all_df[\"date\"].values.tolist()\n",
        "renkyu_ake_list = []\n",
        "\n",
        "for index,udl in enumerate(holi_all_list):\n",
        "  #最大11連休まで考慮\n",
        "  for i in [1,2,3,4,5,6,7,8,9,10,11]:\n",
        "    chk_date = pd.to_datetime(udl) + timedelta(days=i)\n",
        "    chk_date = str(chk_date)[0:10].replace('-', '/')\n",
        "    \n",
        "    if (index+i) == len(holi_all_list):\n",
        "      break\n",
        "    else:\n",
        "      #次の日付[inidex+1]がlistに無い場合=平日と見なす\n",
        "      if chk_date != holi_all_list[index+i]:\n",
        "        renkyu_ake_list.append(chk_date)\n",
        "        renkyu_cnt = 0\n",
        "        break\n",
        "\n",
        "renkyu_ake_list = set(renkyu_ake_list)\n",
        "renkyu_ake_df = pd.DataFrame(renkyu_ake_list,columns=[\"date\"]).sort_values('date', ascending=True).reset_index(drop=True)\n",
        "renkyu_ake_df = renkyu_ake_df.assign(holi_ake_flg=1)\n",
        "\n",
        "#CSV化\n",
        "renkyu_ake_df.to_csv(\"./drive/My Drive/TrainAccident/renkyu_ake.csv\",index=False)\n",
        "\n",
        "add_df = pd.merge(add_df,renkyu_ake_df, on='date' , how='left')#left join\n",
        "add_df.loc[(add_df['holi_ake_flg'].isnull()) ,\"holi_ake_flg\"] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6Fj8lkYK6rJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#キー結合させる為\n",
        "add_df[\"date\"] = add_df['date'].astype('str')\n",
        "\n",
        "#乗車人数\n",
        "base_df = pd.merge(add_df,ninzu_df, on='st' , how='left')#left join\n",
        "\n",
        "#乗車人数を正規化\n",
        "base_df['ninzu'] = base_df['ninzu'].astype('float')\n",
        "base_df = base_df[base_df['ninzu'] > 0]\n",
        "\n",
        "s = base_df['ninzu']\n",
        "base_df['ninzu'] = (s - s.min()) / (s.max() - s.min())\n",
        "\n",
        "#人数をカテゴライズ化(20分割)\n",
        "ninzu_num_df = pd.DataFrame(pd.qcut(base_df['ninzu'], 20,\n",
        "                                         labels=[0,0.05,0.1,0.15,0.2,\n",
        "                                                 0.25,0.3,0.35,0.4,0.45,\n",
        "                                                 0.5,0.55,0.6,0.65,0.7,\n",
        "                                                 0.75,0.8,0.85,0.9,0.95]))\n",
        "ninzu_num_df = ninzu_num_df.rename(columns={'ninzu': 'ninzu_cate'})\n",
        "\n",
        "base_df = pd.concat([base_df,ninzu_num_df],axis=1)\n",
        "base_df[\"ninzu\"] = base_df[\"ninzu_cate\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtvnAKLnNf6y",
        "colab_type": "code",
        "outputId": "cea23b7f-a0ee-4953-9dac-5448b054ae1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "source": [
        "base_df3 = base_df.drop([\"line\",\"from_st\",\"to_st\",\"st\",\"ninzu_cate\"],axis=1)\n",
        "base_df3 = base_df3.assign(flg=1)\n",
        "base_df3.head(10)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>comp_time</th>\n",
              "      <th>day_am_time</th>\n",
              "      <th>day_pm_time</th>\n",
              "      <th>home_time</th>\n",
              "      <th>midnight_time</th>\n",
              "      <th>morning_time</th>\n",
              "      <th>night_time</th>\n",
              "      <th>yobi_0</th>\n",
              "      <th>yobi_1</th>\n",
              "      <th>yobi_2</th>\n",
              "      <th>yobi_3</th>\n",
              "      <th>yobi_4</th>\n",
              "      <th>yobi_5</th>\n",
              "      <th>yobi_6</th>\n",
              "      <th>holiday_flg</th>\n",
              "      <th>holi_ake_flg</th>\n",
              "      <th>ninzu</th>\n",
              "      <th>flg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019/08/10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.65</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019/08/09</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.65</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019/08/07</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019/08/06</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.15</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019/08/05</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2019/08/03</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2019/08/03</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.15</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2019/08/03</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.35</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2019/08/03</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2019/08/01</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          date  comp_time  day_am_time  ...  holi_ake_flg  ninzu  flg\n",
              "0   2019/08/10          0            0  ...           0.0   0.65    1\n",
              "1   2019/08/09          0            0  ...           0.0   0.65    1\n",
              "2   2019/08/07          0            0  ...           0.0   0.60    1\n",
              "3   2019/08/06          0            1  ...           0.0   0.15    1\n",
              "4   2019/08/05          0            1  ...           1.0   0.75    1\n",
              "6   2019/08/03          0            0  ...           0.0   0.30    1\n",
              "7   2019/08/03          1            0  ...           0.0   0.15    1\n",
              "8   2019/08/03          0            0  ...           0.0   0.35    1\n",
              "9   2019/08/03          0            0  ...           0.0   0.50    1\n",
              "10  2019/08/01          0            0  ...           0.0   0.70    1\n",
              "\n",
              "[10 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1do445lDl4uG",
        "colab_type": "text"
      },
      "source": [
        "##▲base_df作成　ここまで\n",
        "##▼make_df作成　ここから"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQrPsbjkN8y8",
        "colab_type": "code",
        "outputId": "427ff663-367b-4da6-e6a0-1b7bdfd6b804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "import numpy as np\n",
        "from datetime import date, timedelta\n",
        "import itertools\n",
        "\n",
        "#日付データ作成\n",
        "dates_df = pd.DataFrame({\"date\": [pd.to_datetime(\"2010-01-01\") + timedelta(days=i) for i in range(3650)]},dtype=\"object\")\n",
        "date_list = dates_df.values.tolist()\n",
        "\n",
        "#デフォルトでは小数点が付いてしまう為、int型に変換\n",
        "time_cate = np.eye(7).astype(int)\n",
        "yobi_cate = np.eye(7).astype(int)\n",
        "#holiday関連(休日flg,休日明けflg)\n",
        "\n",
        "ninzu_list=[0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,\n",
        "            0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95]\n",
        "\n",
        "wk_list = []\n",
        "for wk in date_list:\n",
        "  for wk2 in time_cate:\n",
        "    for wk3 in yobi_cate:\n",
        "      #人数(正規化済)分 繰り返し\n",
        "      for nlist in ninzu_list:\n",
        "        list_parts = np.concatenate((wk,wk2,wk3,0,0,nlist,0), axis=None)\n",
        "        wk_list.append(list_parts.tolist())\n",
        "\n",
        "col=[\"date\",\n",
        "     \"comp_time\",\"day_am_time\",\"day_pm_time\",\"home_time\",\"midnight_time\",\"morning_time\",\"night_time\",\n",
        "     \"yobi_0\",\"yobi_1\",\"yobi_2\",\"yobi_3\",\"yobi_4\",\"yobi_5\",\"yobi_6\",\n",
        "     \"holiday_flg\",\"holi_ake_flg\",\n",
        "     \"ninzu\",\n",
        "     \"flg\"]\n",
        "\n",
        "make_df = pd.DataFrame(data=wk_list,columns=col)\n",
        "\n",
        "make_df['date'] = make_df['date'].astype('str')\n",
        "make_df['date'] = make_df['date'].str.replace('-', '/')\n",
        "\n",
        "#祝日\n",
        "holi_list = holi_df[\"date\"].values.tolist()\n",
        "make_df.loc[(make_df[\"date\"].isin(holi_list)),\"holiday_flg\"] = 1\n",
        "\n",
        "#土日\n",
        "make_df.loc[(make_df['date'].str[5:10].isin(donichi_list)) ,\"holiday_flg\"] = 1\n",
        "\n",
        "#特殊休日\n",
        "Special_holiday_list = [\"08/13\",\"08/14\",\"08/15\",\"08/16\",\"12/29\",\"12/30\",\"12/31\",\"01/02\",\"01/03\",\"01/04\"]\n",
        "make_df.loc[(make_df['date'].str[5:10].isin(Special_holiday_list)) ,\"holiday_flg\"] = 1\n",
        "\n",
        "#平日はALLゼロ\n",
        "make_df.loc[(make_df['holiday_flg'].isnull()) ,\"holiday_flg\"] = 0\n",
        "\n",
        "#休日明け\n",
        "ake_list = renkyu_ake_df[\"date\"].values.tolist()\n",
        "make_df.loc[(make_df[\"date\"].isin(ake_list)),\"holi_ake_flg\"] = 1\n",
        "make_df.loc[(make_df['holi_ake_flg'].isnull()) ,\"holi_ake_flg\"] = 0\n",
        "\n",
        "make_df.head(3)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>comp_time</th>\n",
              "      <th>day_am_time</th>\n",
              "      <th>day_pm_time</th>\n",
              "      <th>home_time</th>\n",
              "      <th>midnight_time</th>\n",
              "      <th>morning_time</th>\n",
              "      <th>night_time</th>\n",
              "      <th>yobi_0</th>\n",
              "      <th>yobi_1</th>\n",
              "      <th>yobi_2</th>\n",
              "      <th>yobi_3</th>\n",
              "      <th>yobi_4</th>\n",
              "      <th>yobi_5</th>\n",
              "      <th>yobi_6</th>\n",
              "      <th>holiday_flg</th>\n",
              "      <th>holi_ake_flg</th>\n",
              "      <th>ninzu</th>\n",
              "      <th>flg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010/01/01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010/01/01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010/01/01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date  comp_time  day_am_time  ...  holi_ake_flg  ninzu  flg\n",
              "0  2010/01/01          1            0  ...             0   0.00    0\n",
              "1  2010/01/01          1            0  ...             0   0.05    0\n",
              "2  2010/01/01          1            0  ...             0   0.10    0\n",
              "\n",
              "[3 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajUb2NM_lrjI",
        "colab_type": "text"
      },
      "source": [
        "##★データセットインポート(make_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcWsBtUEfiWm",
        "colab_type": "code",
        "outputId": "3a373a7a-5d19-4ee1-be4e-20211cecb23d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#make_df.to_csv(\"./drive/My Drive/TrainAccident/make_df.csv\")\n",
        "make_df = pd.read_csv(\"./drive/My Drive/TrainAccident/make_df.csv\",index_col=0)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgHREPg0cfrO",
        "colab_type": "code",
        "outputId": "ee6e807f-64b7-4b0c-bd02-cc6f40e30ff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(base_df3.columns)\n",
        "print(make_df.columns)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['date', 'comp_time', 'day_am_time', 'day_pm_time', 'home_time',\n",
            "       'midnight_time', 'morning_time', 'night_time', 'yobi_0', 'yobi_1',\n",
            "       'yobi_2', 'yobi_3', 'yobi_4', 'yobi_5', 'yobi_6', 'holiday_flg',\n",
            "       'holi_ake_flg', 'ninzu', 'flg'],\n",
            "      dtype='object')\n",
            "Index(['date', 'comp_time', 'day_am_time', 'day_pm_time', 'home_time',\n",
            "       'midnight_time', 'morning_time', 'night_time', 'yobi_0', 'yobi_1',\n",
            "       'yobi_2', 'yobi_3', 'yobi_4', 'yobi_5', 'yobi_6', 'holiday_flg',\n",
            "       'holi_ake_flg', 'ninzu', 'flg'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kPGXH6IS28q",
        "colab_type": "code",
        "outputId": "55c1a4d1-0970-40fd-a984-146ba5d89dd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ret = pd.concat([base_df3, make_df], axis=0)\n",
        "\n",
        "#duplicated()と論理否定演算子~を使って、重複した行を削除したDataFrameを取得できる。\n",
        "ret = ret[~ret.duplicated([\"date\",\n",
        "                           \"comp_time\",\"day_am_time\",\"day_pm_time\",\"home_time\",\"midnight_time\",\"morning_time\",\"night_time\",\n",
        "                           \"yobi_0\",\"yobi_1\",\"yobi_2\",\"yobi_3\",\"yobi_4\",\"yobi_5\",\"yobi_6\",\n",
        "                           \"holiday_flg\",\"holi_ake_flg\",\n",
        "                           \"ninzu\"])]\n",
        "\n",
        "#余分なデータは削除\n",
        "ret = ret[ret[\"date\"] <= \"2019/08/10\"]\n",
        "print(ret.shape)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3438820, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkZH5vs3TN-O",
        "colab_type": "code",
        "outputId": "c1d73dd1-3e2a-4d9a-c511-48b41ba0e672",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#補完したい期間の日付を入れたデータフレームを作ってマージ\n",
        "#https://qiita.com/hanon/items/29cf5ed9acb4f731538f\n",
        "\n",
        "#キー結合させる為\n",
        "ret[\"date\"] = ret['date'].astype('str')\n",
        "\n",
        "#気温\n",
        "temp_df = pd.read_csv(\"./drive/My Drive/TrainAccident/temp.csv\")\n",
        "temp_df = temp_df.dropna(subset=[\"max_temp\"])\n",
        "temp_df = temp_df.dropna(subset=[\"min_temp\"])\n",
        "\n",
        "ret2 = pd.merge(ret,temp_df, on='date' , how='left')#left join\n",
        "\n",
        "#日照時間\n",
        "sun_df = pd.read_csv(\"./drive/My Drive/TrainAccident/suntime.csv\")\n",
        "sun_df = sun_df.dropna(subset=[\"suntime\"])\n",
        "\n",
        "ret3 = pd.merge(ret2,sun_df, on='date' , how='left')#left join\n",
        "\n",
        "#降水量/気圧\n",
        "rain_pres_df = pd.read_csv(\"./drive/My Drive/TrainAccident/rain_pres.csv\")\n",
        "rain_pres_df = rain_pres_df.drop('dmy',axis=1)\n",
        "\n",
        "rain_pres_df['rain'] = rain_pres_df['rain'].astype('float')\n",
        "rain_pres_df['pres'] = rain_pres_df['pres'].astype('float')\n",
        "\n",
        "ret3 = pd.merge(ret3,rain_pres_df, on='date' , how='left')#left join\n",
        "\n",
        "print(ret3.head(3))\n",
        "print(ret3.shape)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         date  comp_time  day_am_time  ...  suntime  rain    pres\n",
            "0  2019/08/10          0            0  ...      9.4   0.0  1005.4\n",
            "1  2019/08/09          0            0  ...     10.8   0.0  1005.5\n",
            "2  2019/08/07          0            0  ...      9.5   0.0  1007.4\n",
            "\n",
            "[3 rows x 24 columns]\n",
            "(3438820, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU7L1WImy-rs",
        "colab_type": "text"
      },
      "source": [
        "##季節ごとの平均気温を算出"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cD-mmHsx4Go",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#日付単位で最高気温を集計\n",
        "#()･･･集計単位項目\n",
        "#[]･･･集計対象項目\n",
        "import numpy as np\n",
        "\n",
        "#listからnumpy.darray型にしないとnumpyの集計関数が使用できない\n",
        "temp_mean_ary = []\n",
        "month_list = [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\"]\n",
        "\n",
        "for m_val in month_list:\n",
        "  max_temp = np.array(temp_df[temp_df.date.str[5:7] == m_val][\"max_temp\"]).mean()\n",
        "  min_temp = np.array(temp_df[temp_df.date.str[5:7] == m_val][\"min_temp\"]).mean()\n",
        "\n",
        "  list_parts = np.concatenate((m_val,max_temp,min_temp), axis=None)\n",
        "  temp_mean_ary.append(list_parts.tolist())\n",
        "\n",
        "col=[\"date\",\"max_temp\",\"min_temp\"]\n",
        "temp_mean_df = pd.DataFrame(data=temp_mean_ary,columns=col)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJZuelRCIp4v",
        "colab_type": "text"
      },
      "source": [
        "##季節ごとの日照時間を算出"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W403t91qIvls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#日付単位で日照時間を集計\n",
        "#()･･･集計単位項目\n",
        "#[]･･･集計対象項目\n",
        "import numpy as np\n",
        "\n",
        "#欠損値削除\n",
        "sun_df = sun_df.dropna()\n",
        "\n",
        "#listからnumpy.darray型にしないとnumpyの集計関数が使用できない\n",
        "sun_mean_ary = []\n",
        "month_list = [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\"]\n",
        "\n",
        "for m_val in month_list:\n",
        "  sun_mean = np.array(sun_df[sun_df.date.str[5:7] == m_val][\"suntime\"]).mean()\n",
        "\n",
        "  list_parts = np.concatenate((m_val,sun_mean), axis=None)\n",
        "  sun_mean_ary.append(list_parts.tolist())\n",
        "\n",
        "col=[\"date\",\"suntime\"]\n",
        "sun_mean_df = pd.DataFrame(data=sun_mean_ary,columns=col)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYyKb9OmWaYF",
        "colab_type": "text"
      },
      "source": [
        "##欠測値を補完"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae1t1acVQQJ3",
        "colab_type": "code",
        "outputId": "b97a8ea3-054c-4c19-a6e2-ffa50556e329",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#欠測日を確認\n",
        "#(set:listの重複を削除)\n",
        "max_temp_chk = set(ret3[ret3[\"max_temp\"].isnull()][\"date\"].values)\n",
        "print(\"最高気温:\",max_temp_chk)\n",
        "\n",
        "min_temp_chk = set(ret3[ret3[\"min_temp\"].isnull()][\"date\"].values)\n",
        "print(\"最低気温:\",min_temp_chk)\n",
        "\n",
        "sun_chk = set(ret3[ret3[\"suntime\"].isnull()][\"date\"].values)\n",
        "print(\"日照時間:\",sun_chk)\n",
        "\n",
        "rain_chk = set(ret3[ret3[\"rain\"].isnull()][\"date\"].values)\n",
        "print(\"降水量:\",rain_chk)\n",
        "\n",
        "pres_chk = set(ret3[ret3[\"pres\"].isnull()][\"date\"].values)\n",
        "print(\"気圧:\",pres_chk)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "最高気温: {'2012/04/04'}\n",
            "最低気温: {'2012/04/04'}\n",
            "日照時間: {'2010/02/18', '2013/05/19', '2017/07/17', '2012/11/09', '2014/02/20', '2014/12/05', '2012/07/23', '2013/05/21', '2017/07/11', '2012/11/08'}\n",
            "降水量: set()\n",
            "気圧: set()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBDNLok5XNe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#最高気温\n",
        "# ret3.loc[(ret3[\"max_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"01\"])),\"max_temp\"] = temp_mean_df.loc[0,\"max_temp\"]\n",
        "# ret3.loc[(ret3[\"max_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"02\"])),\"max_temp\"] = temp_mean_df.loc[1,\"max_temp\"]\n",
        "# ret3.loc[(ret3[\"max_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"03\"])),\"max_temp\"] = temp_mean_df.loc[2,\"max_temp\"]\n",
        "ret3.loc[(ret3[\"max_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"04\"])),\"max_temp\"] = temp_mean_df.loc[3,\"max_temp\"]\n",
        "# ret3.loc[(ret3[\"max_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"05\"])),\"max_temp\"] = temp_mean_df.loc[4,\"max_temp\"]\n",
        "# ret3.loc[(ret3[\"max_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"06\"])),\"max_temp\"] = temp_mean_df.loc[5,\"max_temp\"]\n",
        "# ret3.loc[(ret3[\"max_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"07\"])),\"max_temp\"] = temp_mean_df.loc[6,\"max_temp\"]\n",
        "# ret3.loc[(ret3[\"max_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"08\"])),\"max_temp\"] = temp_mean_df.loc[7,\"max_temp\"]\n",
        "# ret3.loc[(ret3[\"max_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"09\"])),\"max_temp\"] = temp_mean_df.loc[8,\"max_temp\"]\n",
        "# ret3.loc[(ret3[\"max_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"10\"])),\"max_temp\"] = temp_mean_df.loc[9,\"max_temp\"]\n",
        "# ret3.loc[(ret3[\"max_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"11\"])),\"max_temp\"] = temp_mean_df.loc[10,\"max_temp\"]\n",
        "# ret3.loc[(ret3[\"max_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"12\"])),\"max_temp\"] = temp_mean_df.loc[11,\"max_temp\"]\n",
        "\n",
        "#最低気温\n",
        "# ret3.loc[(ret3[\"min_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"01\"])),\"min_temp\"] = temp_mean_df.loc[0,\"min_temp\"]\n",
        "# ret3.loc[(ret3[\"min_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"02\"])),\"min_temp\"] = temp_mean_df.loc[1,\"min_temp\"]\n",
        "# ret3.loc[(ret3[\"min_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"03\"])),\"min_temp\"] = temp_mean_df.loc[2,\"min_temp\"]\n",
        "ret3.loc[(ret3[\"min_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"04\"])),\"min_temp\"] = temp_mean_df.loc[3,\"min_temp\"]\n",
        "# ret3.loc[(ret3[\"min_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"05\"])),\"min_temp\"] = temp_mean_df.loc[4,\"min_temp\"]\n",
        "# ret3.loc[(ret3[\"min_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"06\"])),\"min_temp\"] = temp_mean_df.loc[5,\"min_temp\"]\n",
        "# ret3.loc[(ret3[\"min_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"07\"])),\"min_temp\"] = temp_mean_df.loc[6,\"min_temp\"]\n",
        "# ret3.loc[(ret3[\"min_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"08\"])),\"min_temp\"] = temp_mean_df.loc[7,\"min_temp\"]\n",
        "# ret3.loc[(ret3[\"min_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"09\"])),\"min_temp\"] = temp_mean_df.loc[8,\"min_temp\"]\n",
        "# ret3.loc[(ret3[\"min_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"10\"])),\"min_temp\"] = temp_mean_df.loc[9,\"min_temp\"]\n",
        "# ret3.loc[(ret3[\"min_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"11\"])),\"min_temp\"] = temp_mean_df.loc[10,\"min_temp\"]\n",
        "# ret3.loc[(ret3[\"min_temp\"].isnull()) & (ret3['date'].str[5:7].isin([\"12\"])),\"min_temp\"] = temp_mean_df.loc[11,\"min_temp\"]\n",
        "\n",
        "#日照時間\n",
        "ret3.loc[(ret3[\"suntime\"].isnull()) & (ret3['date'].str[5:7].isin([\"01\"])),\"suntime\"] = sun_mean_df.loc[0,\"suntime\"]\n",
        "ret3.loc[(ret3[\"suntime\"].isnull()) & (ret3['date'].str[5:7].isin([\"02\"])),\"suntime\"] = sun_mean_df.loc[1,\"suntime\"]\n",
        "ret3.loc[(ret3[\"suntime\"].isnull()) & (ret3['date'].str[5:7].isin([\"03\"])),\"suntime\"] = sun_mean_df.loc[2,\"suntime\"]\n",
        "ret3.loc[(ret3[\"suntime\"].isnull()) & (ret3['date'].str[5:7].isin([\"04\"])),\"suntime\"] = sun_mean_df.loc[3,\"suntime\"]\n",
        "ret3.loc[(ret3[\"suntime\"].isnull()) & (ret3['date'].str[5:7].isin([\"05\"])),\"suntime\"] = sun_mean_df.loc[4,\"suntime\"]\n",
        "ret3.loc[(ret3[\"suntime\"].isnull()) & (ret3['date'].str[5:7].isin([\"06\"])),\"suntime\"] = sun_mean_df.loc[5,\"suntime\"]\n",
        "ret3.loc[(ret3[\"suntime\"].isnull()) & (ret3['date'].str[5:7].isin([\"07\"])),\"suntime\"] = sun_mean_df.loc[6,\"suntime\"]\n",
        "ret3.loc[(ret3[\"suntime\"].isnull()) & (ret3['date'].str[5:7].isin([\"08\"])),\"suntime\"] = sun_mean_df.loc[7,\"suntime\"]\n",
        "ret3.loc[(ret3[\"suntime\"].isnull()) & (ret3['date'].str[5:7].isin([\"09\"])),\"suntime\"] = sun_mean_df.loc[8,\"suntime\"]\n",
        "ret3.loc[(ret3[\"suntime\"].isnull()) & (ret3['date'].str[5:7].isin([\"10\"])),\"suntime\"] = sun_mean_df.loc[9,\"suntime\"]\n",
        "ret3.loc[(ret3[\"suntime\"].isnull()) & (ret3['date'].str[5:7].isin([\"11\"])),\"suntime\"] = sun_mean_df.loc[10,\"suntime\"]\n",
        "ret3.loc[(ret3[\"suntime\"].isnull()) & (ret3['date'].str[5:7].isin([\"12\"])),\"suntime\"] = sun_mean_df.loc[11,\"suntime\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2qDKOcSPjrO",
        "colab_type": "code",
        "outputId": "eaad21e3-651e-4b9c-86d5-0bb1bdfd8837",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "#予測に不要な項目を削除\n",
        "ret4 = ret3.copy().drop([\"date\"], axis=1)\n",
        "\n",
        "#カラム「max_temp」「min_temp」を元に「diff_temp」を作成\n",
        "ret5 = ret4.assign(diff_temp=ret4['max_temp'].astype(float)-ret4['min_temp'].astype(float))\n",
        "\n",
        "print(ret5.head())\n",
        "print(ret5.shape)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   comp_time  day_am_time  day_pm_time  ...  rain    pres  diff_temp\n",
            "0          0            0            0  ...   0.0  1005.4        7.7\n",
            "1          0            0            0  ...   0.0  1005.5        6.4\n",
            "2          0            0            0  ...   0.0  1007.4        6.0\n",
            "3          0            1            0  ...   0.0  1008.4        5.6\n",
            "4          0            1            0  ...   0.0  1009.5        7.7\n",
            "\n",
            "[5 rows x 24 columns]\n",
            "(3438820, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oANaC4eVj2vE",
        "colab_type": "code",
        "outputId": "694771b3-ce01-4e48-920d-fb7f69a6fd90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "#型変換\n",
        "ret5['max_temp'] = ret5['max_temp'].astype('float')\n",
        "ret5['min_temp'] = ret5['min_temp'].astype('float')\n",
        "ret5['diff_temp'] = ret5['diff_temp'].astype('float')\n",
        "ret5['suntime'] = ret5['suntime'].astype('float')\n",
        "ret5['rain'] = ret5['rain'].astype('float')\n",
        "ret5['pres'] = ret5['pres'].astype('float')\n",
        "\n",
        "#正規化\n",
        "ret_ = ret5.copy()\n",
        "\n",
        "s = ret_['max_temp']\n",
        "ret_['max_temp'] = (s - s.min()) / (s.max() - s.min())\n",
        "\n",
        "s = ret_['min_temp']\n",
        "ret_['min_temp'] = (s - s.min()) / (s.max() - s.min())\n",
        "\n",
        "s = ret_['suntime']\n",
        "ret_['suntime'] = (s - s.min()) / (s.max() - s.min())\n",
        "\n",
        "s = ret_['rain']\n",
        "ret_['rain'] = (s - s.min()) / (s.max() - s.min())\n",
        "\n",
        "s = ret_['pres']\n",
        "ret_['pres'] = (s - s.min()) / (s.max() - s.min())\n",
        "\n",
        "s = ret_['diff_temp']\n",
        "ret_['diff_temp'] = (s - s.min()) / (s.max() - s.min())\n",
        "\n",
        "ret = ret_.copy()\n",
        "print(ret.head())\n",
        "print(ret.shape)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   comp_time  day_am_time  day_pm_time  ...  rain      pres  diff_temp\n",
            "0          0            0            0  ...   0.0  0.519626   0.358696\n",
            "1          0            0            0  ...   0.0  0.521495   0.288043\n",
            "2          0            0            0  ...   0.0  0.557009   0.266304\n",
            "3          0            1            0  ...   0.0  0.575701   0.244565\n",
            "4          0            1            0  ...   0.0  0.596262   0.358696\n",
            "\n",
            "[5 rows x 24 columns]\n",
            "(3438820, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijB-UEAzJlBx",
        "colab_type": "code",
        "outputId": "97b5572f-5f71-4f5c-814a-f77df69059fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#不均衡データであることを確認する。\n",
        "print(ret[\"flg\"].value_counts())"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    3433817\n",
            "1       5003\n",
            "Name: flg, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IewDb5IzJyWX",
        "colab_type": "code",
        "outputId": "f2410976-02c0-4719-d8da-3ebd0dda2f64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#ダウンサンプリング\n",
        "!pip install imbalanced-learn\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "# ラベルと入力データに分離する\n",
        "y = ret.loc[:,\"flg\"]\n",
        "y = y.values.tolist()\n",
        "\n",
        "x = ret.loc[:,[\n",
        "               \"comp_time\",\"day_am_time\",\"day_pm_time\",\"home_time\",\"midnight_time\",\"morning_time\",\"night_time\",\n",
        "               \"yobi_0\",\"yobi_1\",\"yobi_2\",\"yobi_3\",\"yobi_4\",\"yobi_5\",\"yobi_6\",\n",
        "               \"holiday_flg\",\"holi_ake_flg\",\n",
        "               \"ninzu\",\"max_temp\",\"min_temp\",\"suntime\",\"rain\",\"pres\",\"diff_temp\"]]\n",
        "\n",
        "#ダウンサンプリング\n",
        "sampler = RandomUnderSampler(random_state=42)\n",
        "X_resampled, y_resampled = sampler.fit_resample(x, y)\n",
        "print(X_resampled.shape)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.6/dist-packages (0.4.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.21.3)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->imbalanced-learn) (0.13.2)\n",
            "(10006, 23)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR0nUQzqaea0",
        "colab_type": "code",
        "outputId": "9d26d3fe-c68c-42ba-d6e5-e685bfbe0508",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#再データフレーム化\n",
        "X_resampled2 = pd.DataFrame(X_resampled,columns=[\n",
        "                                                 \"comp_time\",\"day_am_time\",\"day_pm_time\",\"home_time\",\"midnight_time\",\"morning_time\",\"night_time\",\n",
        "                                                 \"yobi_0\",\"yobi_1\",\"yobi_2\",\"yobi_3\",\"yobi_4\",\"yobi_5\",\"yobi_6\",\n",
        "                                                 \"holiday_flg\",\"holi_ake_flg\",\n",
        "                                                 \"ninzu\",\"max_temp\",\"min_temp\",\"suntime\",\"rain\",\"pres\",\"diff_temp\"])\n",
        "y_resampled2 = pd.DataFrame(y_resampled,columns=[\"flg\"])\n",
        "\n",
        "#結合\n",
        "resmp_df = pd.concat([X_resampled2, y_resampled2],axis=1).reset_index(drop=True)\n",
        "\n",
        "resmp_df.to_csv(\"./drive/My Drive/TrainAccident/AccidentResample.csv\",index=False)\n",
        "\n",
        "#均衡データになったことを確認する。\n",
        "print(resmp_df[\"flg\"].value_counts())"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    5003\n",
            "0    5003\n",
            "Name: flg, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN8VtVlcoH_C",
        "colab_type": "text"
      },
      "source": [
        "##検証1(Classifier)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4M0LUZlEaXIq",
        "outputId": "914193ea-75ba-459e-e457-bdcb0183c0e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# ラベルと入力データに分離する\n",
        "y = resmp_df.loc[:,\"flg\"]\n",
        "y = y.values.tolist()\n",
        "x = resmp_df.drop([\"flg\"],axis=1)\n",
        "\n",
        "# 学習用とテスト用に分離する\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, train_size = 0.8, shuffle = True)\n",
        "\n",
        "# 学習する\n",
        "model = GradientBoostingClassifier ()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# 評価する\n",
        "y_pred = model.predict(x_test)\n",
        "print(\"正解率 = \" , accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n",
        "#参考：日本の天気予報は正解率87%"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "正解率 =  0.6418581418581418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS2hrilSOCAO",
        "colab_type": "code",
        "outputId": "128400a5-f0e6-427c-c591-3f310a2cde1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "#説明変数の影響度合\n",
        "#Classifierの場合\n",
        "importances = model.feature_importances_\n",
        "df_ft_name_df = pd.DataFrame(x.columns.tolist(),columns=[\"name\"])\n",
        "df_ft_val_df = pd.DataFrame(importances.tolist(),columns=[\"val\"])\n",
        "\n",
        "imp_df = pd.concat([df_ft_name_df,df_ft_val_df],axis=1).sort_values('val', ascending=False).reset_index(drop=True)\n",
        "imp_df.head(10)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>yobi_0</td>\n",
              "      <td>0.227153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>midnight_time</td>\n",
              "      <td>0.157778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>holi_ake_flg</td>\n",
              "      <td>0.155926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>morning_time</td>\n",
              "      <td>0.142703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pres</td>\n",
              "      <td>0.050913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>max_temp</td>\n",
              "      <td>0.040634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>diff_temp</td>\n",
              "      <td>0.038066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>min_temp</td>\n",
              "      <td>0.034745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>rain</td>\n",
              "      <td>0.028128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>home_time</td>\n",
              "      <td>0.027716</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            name       val\n",
              "0         yobi_0  0.227153\n",
              "1  midnight_time  0.157778\n",
              "2   holi_ake_flg  0.155926\n",
              "3   morning_time  0.142703\n",
              "4           pres  0.050913\n",
              "5       max_temp  0.040634\n",
              "6      diff_temp  0.038066\n",
              "7       min_temp  0.034745\n",
              "8           rain  0.028128\n",
              "9      home_time  0.027716"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RsNqqcCUvjY",
        "colab_type": "code",
        "outputId": "861631f8-5ce4-4449-9d7c-bfb6c8e1c0c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#真陽性率 (Recall)\n",
        "#Positive なデータに対してモデルがどれだけ正解できているかを確認\n",
        "from sklearn.metrics import recall_score\n",
        "print(\"真陽性率 = \",recall_score(y_test, y_pred))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "真陽性率 =  0.7514677103718199\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCCe9jG2YfQN",
        "colab_type": "code",
        "outputId": "0af28044-4d08-4f9d-eeb7-212bdfdf9e0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#適合率 (Precision) \n",
        "#モデルが Positive と判断したデータの中に、どれだけ本当に Positive なものがあったかを確認\n",
        "from sklearn.metrics import precision_score\n",
        "print(\"適合率 = \",precision_score(y_test, y_pred))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "適合率 =  0.6238830219333875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKeucIp_czsR",
        "colab_type": "code",
        "outputId": "0647d3cb-44d8-4045-ac64-bc6ca3abdc3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#他のアルゴリズムの場合の予測\n",
        "import warnings\n",
        "from sklearn.utils.testing import all_estimators\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# classifierのアルゴリズム全てを取得する --- (*1)\n",
        "warnings.filterwarnings('ignore')\n",
        "allAlgorithms = all_estimators(type_filter=\"classifier\")\n",
        "\n",
        "for(name, algorithm) in allAlgorithms:\n",
        "\n",
        "    #エラー回避\n",
        "    if name == 'GradientBoostingClassifier' or name == 'RandomForestClassifier' or name == 'KNeighborsClassifier' or name == 'LogisticRegression' or name == 'LogisticRegressionCV':\n",
        "\n",
        "      # 各アリゴリズムのオブジェクトを作成 --- (*2)\n",
        "      # 注意:一部のアルゴリズムは引数に何かを渡さないとエラーになる。\n",
        "      clf = algorithm()\n",
        "\n",
        "      # 学習して、評価する --- (*3)\n",
        "      #( x_train : 学習用データ / learn_label : ラベル)\n",
        "      clf.fit(x_train, y_train)\n",
        "      y_pred = clf.predict(x_test)\n",
        "      print(name,\"の正解率 = \" , accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GradientBoostingClassifier の正解率 =  0.6418581418581418\n",
            "KNeighborsClassifier の正解率 =  0.6293706293706294\n",
            "LogisticRegression の正解率 =  0.5979020979020979\n",
            "LogisticRegressionCV の正解率 =  0.596903096903097\n",
            "RandomForestClassifier の正解率 =  0.6243756243756243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VSr1z6zMjLh",
        "colab_type": "text"
      },
      "source": [
        "##検証2(スタッキング)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2sdyyvdTv9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from copy import deepcopy\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "class StackingClassifier:\n",
        "  def __init__(self, estimators, merge_estimator):\n",
        "    self.original_clfs = dict(estimators)\n",
        "    self.m_clf = merge_estimator\n",
        "\n",
        "    self.clfs_dict = defaultdict(list)\n",
        "    self.clfs_index = sorted(self.original_clfs.keys())\n",
        "\n",
        "  def fit(self, X2, y2):\n",
        "    self.clfs_dict = defaultdict(list)\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=15)\n",
        "    #random_state=None, shuffle=False\n",
        "    index_list = list(skf.split(X2, y2))\n",
        "    \n",
        "    merge_feature_list = []\n",
        "\n",
        "    for clf_name in self.clfs_index:\n",
        "      clf_origin = self.original_clfs[clf_name]\n",
        "      preds_tmp_list = []\n",
        "      for train_index, test_index in index_list:\n",
        "        clf_copy = deepcopy(clf_origin)\n",
        "        print(\"↓!!!!ここでエラー!!!!\")\n",
        "        print(\"idx:\",train_index)\n",
        "        clf_copy.fit(X2[train_index], y2[train_index])\n",
        "        preds_tmp_list.append(\n",
        "            clf_copy.predict_proba(X2[test_index]))\n",
        "        self.clfs_dict[clf_name].append(clf_copy)\n",
        "      merge_feature_list.append(np.vstack(preds_tmp_list))\n",
        "\n",
        "    X_merged = np.hstack(merge_feature_list)\n",
        "    y_merged = np.hstack([y2[test_index] \n",
        "                          for _, test_index in index_list])\n",
        "\n",
        "    self.m_clf.fit(X_merged, y_merged)\n",
        "    return self\n",
        "\n",
        "        \n",
        "    def predict(self, X2):\n",
        "      merge_feature_list = []\n",
        "      for clf_name in self.clfs_index:\n",
        "        tmp_proba_list = []\n",
        "        for clf in self.clfs_dict[clf_name]:\n",
        "          tmp_proba_list.append(clf.predict_proba(X2))\n",
        "        merge_feature_list.append(\n",
        "          np.mean(tmp_proba_list, axis=0))\n",
        "      X_merged = np.hstack(merge_feature_list)\n",
        "\n",
        "      return self.m_clf.predict(X_merged)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11bU5Q05Mm_b",
        "colab_type": "code",
        "outputId": "191a0e63-18df-47b1-9806-7bc65e47c0ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
        "from sklearn.naive_bayes import GaussianNB as GNB\n",
        "from sklearn.ensemble import RandomForestClassifier as RFC\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "#スタッキング参考\n",
        "#https://www.haya-programming.com/entry/2018/02/17/035058\n",
        "\n",
        "#自前class\n",
        "#(stacking.pyの中の「StackingClassifier」を読み込みたい場合)\n",
        "#from stacking import StackingClassifier\n",
        "import stacking\n",
        "\n",
        "def main():\n",
        "\n",
        "  # ラベルと入力データに分離する\n",
        "  y2 = resmp_df.loc[:,\"flg\"]\n",
        "  y2 = y2.values.tolist()\n",
        "  x2 = resmp_df.drop([\"flg\"],axis=1)\n",
        "\n",
        "  # 学習用とテスト用に分離する\n",
        "  X_train2, X_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size = 0.2, train_size = 0.8, shuffle = True)\n",
        "\n",
        "  svm = SVC(C=5, gamma=0.001, probability=True)\n",
        "  lr = LogisticRegression()\n",
        "  knn = KNN(n_jobs=-1)\n",
        "  nb = GNB()\n",
        "  rfc = RFC(n_estimators=500, n_jobs=-1)\n",
        "  bgg = BaggingClassifier(n_estimators=300, n_jobs=-1)\n",
        "  mlp = MLPClassifier(hidden_layer_sizes=(40, 20), max_iter=1000)\n",
        "\n",
        "  estimators = list(zip([\"svm\",\"lr\",\"knn\",\"nb\",\"rfc\",\"bgg\",\"mlp\"],\n",
        "                        [svm,lr,knn,nb,rfc,bgg,mlp]))\n",
        "  for name, clf in estimators:\n",
        "    #別関数へ\n",
        "    clf.fit(X_train2, y_train2)\n",
        "    preds = clf.predict(X_test2)\n",
        "    print(name)\n",
        "    print(\"p:{0:.4f} r:{1:.4f} f1:{2:.4f}\".format(\n",
        "      *precision_recall_fscore_support(y_test2, preds, average=\"macro\")))\n",
        "\n",
        "#     for v in [\"hard\", \"soft\"]:\n",
        "#         vc_hard = VotingClassifier(estimators, voting=v)\n",
        "#         vc_hard.fit(X_train, y_train)\n",
        "#         preds = vc_hard.predict(X_test)\n",
        "#         print(v, \"voting\")\n",
        "#         print(\"p:{0:.4f} r:{1:.4f} f1:{2:.4f}\".format(\n",
        "#             *precision_recall_fscore_support(y_test, preds, average=\"macro\")))\n",
        "\n",
        "  stcl = StackingClassifier(estimators, RFC(n_estimators=2000, n_jobs=-1))\n",
        "  stcl.fit(X_train2, y_train2)\n",
        "  preds = stcl.predict(X_test2)\n",
        "  print(\"stacking\")\n",
        "  print(\"p:{0:.4f} r:{1:.4f} f1:{2:.4f}\".format(\n",
        "    *precision_recall_fscore_support(y_test2, preds, average=\"macro\")))\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "svm\n",
            "p:0.5876 r:0.5765 f1:0.5653\n",
            "lr\n",
            "p:0.5775 r:0.5709 f1:0.5637\n",
            "knn\n",
            "p:0.6236 r:0.6236 f1:0.6236\n",
            "nb\n",
            "p:0.6171 r:0.5869 f1:0.5624\n",
            "rfc\n",
            "p:0.6465 r:0.6461 f1:0.6462\n",
            "bgg\n",
            "p:0.6170 r:0.6167 f1:0.6167\n",
            "mlp\n",
            "p:0.6507 r:0.6489 f1:0.6486\n",
            "↓!!!!ここでエラー!!!!\n",
            "idx: [ 532  533  535 ... 8001 8002 8003]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-121-81c3979a44e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-121-81c3979a44e3>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0mstcl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRFC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m   \u001b[0mstcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stacking\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-120-00b6ef7579d6>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X2, y2)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"↓!!!!ここでエラー!!!!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"idx:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mclf_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         preds_tmp_list.append(\n\u001b[1;32m     33\u001b[0m             clf_copy.predict_proba(X2[test_index]))\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[0;32m-> 2934\u001b[0;31m                                                    raise_missing=True)\n\u001b[0m\u001b[1;32m   2935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[1;32m   1353\u001b[0m                           raise_missing}\n\u001b[0;32m-> 1354\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[1;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1244\u001b[0m                 raise KeyError(\n\u001b[1;32m   1245\u001b[0m                     u\"None of [{key}] are in the [{axis}]\".format(\n\u001b[0;32m-> 1246\u001b[0;31m                         key=key, axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([ 532,  533,  535,  537,  538,  539,  540,  541,  542,  543,\\n            ...\\n            7994, 7995, 7996, 7997, 7998, 7999, 8000, 8001, 8002, 8003],\\n           dtype='int64', length=7470)] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rREX_w-qOzON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pickleでモデルを保存\n",
        "import pickle\n",
        "\n",
        "filename = './drive/My Drive/TrainAccident/Accident_model_0903.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}