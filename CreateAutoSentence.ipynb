{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CreateAutoSentence.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soichi-fujiwara/jupyter-notebook/blob/master/CreateAutoSentence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPwKibaAiWY_",
        "colab_type": "text"
      },
      "source": [
        "##RNNを使った文章の自動生成\n",
        "https://www.pytry3g.com/entry/2018/03/16/203414"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs0GcghVX522",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "8defe6e1-6cf4-4c5a-c167-d2398e478b78"
      },
      "source": [
        "!pip install beautifulsoup4\n",
        "!pip install mecab-python3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n",
            "Collecting mecab-python3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/92/e7e7f38df8457fa40c1ca86928be5ddbe2bf341e90a35e6ada30d03ef16d/mecab_python3-0.996.2-cp36-cp36m-manylinux1_x86_64.whl (15.9MB)\n",
            "\u001b[K     |████████████████████████████████| 15.9MB 1.6MB/s \n",
            "\u001b[?25hInstalling collected packages: mecab-python3\n",
            "Successfully installed mecab-python3-0.996.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lCt8HpnVzOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import MeCab\n",
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AWcXLszXbhF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f21b2362-da69-4ab0-9cee-0b1982abce38"
      },
      "source": [
        "### データの用意 ###\n",
        "# Wikipediaの記事をダウンロード\n",
        "url = \"http://ja.wikipedia.org/wiki/\"\n",
        "# 記事のリスト\n",
        "wiki_name_list = [\"小島よしお\"]\n",
        "# データを入れる\n",
        "corpus = []\n",
        "tagger = MeCab.Tagger('-Owakati')\n",
        "for wiki_name in wiki_name_list:\n",
        "    # 指定したページの情報を取得\n",
        "    response = requests.get(url+wiki_name)\n",
        "    # HTMLフォーマットに変換\n",
        "    html = response.text\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    # pタグで囲まれた部分を抽出\n",
        "    for p_tag in soup.find_all('p'):\n",
        "        sentences = p_tag.text.strip()\n",
        "        for sentence in sentences.split(\"。\"):\n",
        "            if len(sentence.strip()) == 0:\n",
        "                continue\n",
        "            # 前処理\n",
        "            sentence = re.sub(r\"\\[[0-9]+\\]\", \"\", sentence)\n",
        "            sentence = re.sub(r\"\\[注釈 [0-9]+\\]\", \"\", sentence)\n",
        "            tokens = tagger.parse(sentence).strip().split()\n",
        "            #文章がある程度の長さになったら句読点を付ける。\n",
        "            if len(tokens) > 46:\n",
        "                continue\n",
        "            corpus.append(sentence+\"。\")\n",
        "print(corpus[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "小島 よしお（こじま よしお、1980年11月16日 - ）は、日本のお笑いタレントである。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXF6L4_Fucx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(data=corpus)\n",
        "df.to_csv(\"text.txt\",index=False,header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGXGZqjDDJWw",
        "colab_type": "text"
      },
      "source": [
        "##マルコフ連鎖で文章作成\n",
        "https://chishiki-motomeru.com/post/20190329/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5jI6NBxCLyR",
        "colab_type": "code",
        "outputId": "e25d810f-c214-4fcb-84cb-db56a3771afc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!pip install janome"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting janome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/7c/560f4c9ff01a584b1ecd1da981e82d0077c079ecba84571b4f623680300e/Janome-0.3.9-py2.py3-none-any.whl (25.1MB)\n",
            "\u001b[K     |████████████████████████████████| 25.1MB 18.9MB/s \n",
            "\u001b[?25hInstalling collected packages: janome\n",
            "Successfully installed janome-0.3.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJnEUwO3ixQ-",
        "colab_type": "code",
        "outputId": "563efd5e-8a64-4d3d-b069-312c1ab12151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from janome.tokenizer import Tokenizer\n",
        "import re\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "markov = {}\n",
        "sentence = ''\n",
        "\n",
        "#janomeを使用して文章をパースさせる。\n",
        "def parse(text):\n",
        "    \n",
        "    t = Tokenizer()\n",
        "    tokens = t.tokenize(text)\n",
        "    result = []\n",
        "    for token in tokens:\n",
        "        result.append(token.surface)\n",
        "    return(result)\n",
        "\n",
        "#取得したファイルネームから、改行を除去した上でパースする関数を呼び出す。\n",
        "#ワードリストに代入して、それを返却させる。\n",
        "def get_morpheme(filename):\n",
        "\n",
        "    with open(filename,\"r\",encoding = \"utf_8\") as f:\n",
        "        text = f.read()\n",
        "    text = re.sub(\"\\n\",\"\",text)\n",
        "    \n",
        "    #=================================================\n",
        "    #★この処理が異常に遅い\n",
        "    #=================================================\n",
        "    wordlist = parse(text)\n",
        "    \n",
        "    pickle.dump(wordlist, open('wordlist.binaryfile', 'wb'))\n",
        "\n",
        "    return wordlist\n",
        "\n",
        "#マルコフ辞書を生成させるmarkovは辞書型\n",
        "def create_markov(wordlist):\n",
        "\n",
        "    p1 = \"\"\n",
        "    p2 = \"\"\n",
        "    p3 = \"\"\n",
        "    \n",
        "    #連続した単語に続く、次の単語をサフィックスとする。単語の並びが同じであればそこに二個目のサフィックスが追加される\n",
        "    for word in wordlist:\n",
        "        if p1 and p2 and p3:\n",
        "            if (p1,p2,p3) not in markov:\n",
        "                markov[(p1,p2,p3)] = []\n",
        "            markov[(p1,p2,p3)].append(word)\n",
        "        p1,p2,p3 = p2,p3,word\n",
        "\n",
        "    #プレフィックスの3つに続くサフィックスを表示する。\n",
        "    #print(\"マルコフ辞書の中身:{}\".format(markov))\n",
        "    #print()\n",
        "\n",
        "#マルコフ辞書からsentenceに文字列を格納させる。\n",
        "def generate(wordlist):\n",
        "\n",
        "    global sentence\n",
        "\n",
        "    #3つのプレフィックスをランダムに取得して、それをプレフィックスに代入させる。\n",
        "    p1,p2,p3 = random.choice(list(markov.keys()))\n",
        "\n",
        "    print(\"マルコフ連鎖のキー[{},{},{}]\".format(p1,p2,p3))\n",
        "    print()\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    print(\"【長さ】\",len(wordlist))\n",
        "    #while count < len(wordlist):\n",
        "    while count < 10:\n",
        "        if ((p1,p2,p3) in markov ) == True:\n",
        "            tmp = random.choice(markov[(p1,p2,p3)])\n",
        "            sentence += tmp\n",
        "        p1,p2,p3 = p2,p3,tmp\n",
        "        count += 1\n",
        "\n",
        "    sentence = re.sub(\"^.+?\",\"\",sentence)\n",
        "\n",
        "    if re.search(\".+。\",sentence):\n",
        "        sentence = re.search(\".+。\",sentence).group()\n",
        "\n",
        "    sentence = re.sub(\"」\",\"\",sentence)\n",
        "    sentence = re.sub(\"「\",\"\",sentence)\n",
        "    sentence = re.sub(\"　\",\"\",sentence)\n",
        "\n",
        "    #print(\"【重複カット前】\",sentence)\n",
        "\n",
        "#重複した文章を取り除く。sprit(\"。\")にすることで一文単位でリスト化できる。最終的にリストを文字列型に戻す。\n",
        "#一文単位でリスト化しているので、ですますが連続した場合はここで対処できる。\n",
        "def overlap():\n",
        "\n",
        "    global  sentence\n",
        "\n",
        "    sentence = sentence.split(\"。\")\n",
        "\n",
        "    #空白リストを除去する\n",
        "    if \"\" in sentence:\n",
        "        sentence.remove(\"\")\n",
        "\n",
        "    #この工程で一文の末尾に。を付ける。\n",
        "    new = []\n",
        "    for str in sentence:\n",
        "        str = str + \"。\"\n",
        "        if str == \"。\":\n",
        "            break\n",
        "        new.append(str)\n",
        "\n",
        "    #set関数を使用して、文章の重複を取り除いている\n",
        "    new = set(new)\n",
        "\n",
        "    #set関数を使用しているので、元のリストと文章の順序が異なっている。\n",
        "    #文章の順序についてはこの時点で修正したほうが良さそう\n",
        "    sentence=\"\".join(new)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    #①この中のparceが重い\n",
        "    #word_list = get_morpheme(\"inputText.txt\")\n",
        "    #①'ファイルから読み取り\n",
        "    word_list = pickle.load(open('wordlist.binaryfile', 'rb'))\n",
        "    \n",
        "    create_markov(word_list)\n",
        "\n",
        "    while(not sentence):\n",
        "        generate(word_list)\n",
        "        overlap()\n",
        "\n",
        "    print(\"【文章】\",sentence)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "マルコフ連鎖のキー[さ,れる,出入国]\n",
            "\n",
            "【長さ】 618197\n",
            "【文章】 留管理庁長官の登録を取り消すこと、被。\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}