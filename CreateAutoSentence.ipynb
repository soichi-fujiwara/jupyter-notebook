{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CreateAutoSentence.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soichi-fujiwara/jupyter-notebook/blob/master/CreateAutoSentence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPwKibaAiWY_",
        "colab_type": "text"
      },
      "source": [
        "##RNNを使った文章の自動生成\n",
        "https://www.pytry3g.com/entry/2018/03/16/203414"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs0GcghVX522",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "8defe6e1-6cf4-4c5a-c167-d2398e478b78"
      },
      "source": [
        "!pip install beautifulsoup4\n",
        "!pip install mecab-python3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n",
            "Collecting mecab-python3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/92/e7e7f38df8457fa40c1ca86928be5ddbe2bf341e90a35e6ada30d03ef16d/mecab_python3-0.996.2-cp36-cp36m-manylinux1_x86_64.whl (15.9MB)\n",
            "\u001b[K     |████████████████████████████████| 15.9MB 1.6MB/s \n",
            "\u001b[?25hInstalling collected packages: mecab-python3\n",
            "Successfully installed mecab-python3-0.996.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lCt8HpnVzOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import MeCab\n",
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AWcXLszXbhF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f21b2362-da69-4ab0-9cee-0b1982abce38"
      },
      "source": [
        "### データの用意 ###\n",
        "# Wikipediaの記事をダウンロード\n",
        "url = \"http://ja.wikipedia.org/wiki/\"\n",
        "# 記事のリスト\n",
        "wiki_name_list = [\"小島よしお\"]\n",
        "# データを入れる\n",
        "corpus = []\n",
        "tagger = MeCab.Tagger('-Owakati')\n",
        "for wiki_name in wiki_name_list:\n",
        "    # 指定したページの情報を取得\n",
        "    response = requests.get(url+wiki_name)\n",
        "    # HTMLフォーマットに変換\n",
        "    html = response.text\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    # pタグで囲まれた部分を抽出\n",
        "    for p_tag in soup.find_all('p'):\n",
        "        sentences = p_tag.text.strip()\n",
        "        for sentence in sentences.split(\"。\"):\n",
        "            if len(sentence.strip()) == 0:\n",
        "                continue\n",
        "            # 前処理\n",
        "            sentence = re.sub(r\"\\[[0-9]+\\]\", \"\", sentence)\n",
        "            sentence = re.sub(r\"\\[注釈 [0-9]+\\]\", \"\", sentence)\n",
        "            tokens = tagger.parse(sentence).strip().split()\n",
        "            if len(tokens) > 46:\n",
        "                continue\n",
        "            corpus.append(sentence+\"。\")\n",
        "print(corpus[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "小島 よしお（こじま よしお、1980年11月16日 - ）は、日本のお笑いタレントである。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXF6L4_Fucx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(data=corpus)\n",
        "df.to_csv(\"text.txt\",index=False,header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGXGZqjDDJWw",
        "colab_type": "text"
      },
      "source": [
        "##マルコフ連鎖で文章作成\n",
        "https://chishiki-motomeru.com/post/20190329/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5jI6NBxCLyR",
        "colab_type": "code",
        "outputId": "e25d810f-c214-4fcb-84cb-db56a3771afc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!pip install janome"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting janome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/7c/560f4c9ff01a584b1ecd1da981e82d0077c079ecba84571b4f623680300e/Janome-0.3.9-py2.py3-none-any.whl (25.1MB)\n",
            "\u001b[K     |████████████████████████████████| 25.1MB 18.9MB/s \n",
            "\u001b[?25hInstalling collected packages: janome\n",
            "Successfully installed janome-0.3.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJnEUwO3ixQ-",
        "colab_type": "code",
        "outputId": "143368a4-0630-4717-b5a1-042a1ba18397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        }
      },
      "source": [
        "from janome.tokenizer import Tokenizer\n",
        "import re\n",
        "import random\n",
        "\n",
        "markov = {}\n",
        "sentence = ''\n",
        "\n",
        "#janomeを使用して文章をパースさせる。\n",
        "def parse(text):\n",
        "    \n",
        "    t = Tokenizer()\n",
        "    tokens = t.tokenize(text)\n",
        "    result = []\n",
        "    for token in tokens:\n",
        "        result.append(token.surface)\n",
        "    return(result)\n",
        "\n",
        "#取得したファイルネームから、改行を除去した上でパースする関数を呼び出す。\n",
        "#ワードリストに代入して、それを返却させる。\n",
        "def get_morpheme(filename):\n",
        "\n",
        "    with open(filename,\"r\",encoding = \"utf_8\") as f:\n",
        "        text = f.read()\n",
        "    text = re.sub(\"\\n\",\"\",text)\n",
        "    \n",
        "    #★この処理が異常に遅い\n",
        "    wordlist = parse(text)\n",
        "\n",
        "    return wordlist\n",
        "\n",
        "#マルコフ辞書を生成させるmarkovは辞書型\n",
        "def create_markov(wordlist):\n",
        "\n",
        "    p1 = \"\"\n",
        "    p2 = \"\"\n",
        "    p3 = \"\"\n",
        "    \n",
        "    #連続した単語に続く、次の単語をサフィックスとする。単語の並びが同じであればそこに二個目のサフィックスが追加される\n",
        "    for word in wordlist:\n",
        "        if p1 and p2 and p3:\n",
        "            if (p1,p2,p3) not in markov:\n",
        "                markov[(p1,p2,p3)] = []\n",
        "            markov[(p1,p2,p3)].append(word)\n",
        "        p1,p2,p3 = p2,p3,word\n",
        "\n",
        "    #プレフィックスの3つに続くサフィックスを表示する。\n",
        "    #print(\"マルコフ辞書の中身:{}\".format(markov))\n",
        "    #print()\n",
        "\n",
        "#マルコフ辞書からsentenceに文字列を格納させる。\n",
        "def generate(wordlist):\n",
        "\n",
        "    global sentence\n",
        "\n",
        "    #3つのプレフィックスをランダムに取得して、それをプレフィックスに代入させる。\n",
        "    p1,p2,p3 = random.choice(list(markov.keys()))\n",
        "\n",
        "    print(\"マルコフ連鎖のキー[{},{},{}]\".format(p1,p2,p3))\n",
        "    print()\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    print(\"【長さ】\",len(wordlist))\n",
        "    #while count < len(wordlist):\n",
        "    while count < 200:\n",
        "        if ((p1,p2,p3) in markov ) == True:\n",
        "            tmp = random.choice(markov[(p1,p2,p3)])\n",
        "            sentence += tmp\n",
        "        p1,p2,p3 = p2,p3,tmp\n",
        "        count += 1\n",
        "\n",
        "    sentence = re.sub(\"^.+?\",\"\",sentence)\n",
        "\n",
        "    if re.search(\".+。\",sentence):\n",
        "        sentence = re.search(\".+。\",sentence).group()\n",
        "\n",
        "    sentence = re.sub(\"」\",\"\",sentence)\n",
        "    sentence = re.sub(\"「\",\"\",sentence)\n",
        "    sentence = re.sub(\"　\",\"\",sentence)\n",
        "\n",
        "    #print(\"【重複カット前】\",sentence)\n",
        "\n",
        "#重複した文章を取り除く。sprit(\"。\")にすることで一文単位でリスト化できる。最終的にリストを文字列型に戻す。\n",
        "#一文単位でリスト化しているので、ですますが連続した場合はここで対処できる。\n",
        "def overlap():\n",
        "\n",
        "    global  sentence\n",
        "\n",
        "    sentence = sentence.split(\"。\")\n",
        "\n",
        "    #空白リストを除去する\n",
        "    if \"\" in sentence:\n",
        "        sentence.remove(\"\")\n",
        "\n",
        "    #この工程で一文の末尾に。を付ける。\n",
        "    new = []\n",
        "    for str in sentence:\n",
        "        str = str + \"。\"\n",
        "        if str == \"。\":\n",
        "            break\n",
        "        new.append(str)\n",
        "\n",
        "    #set関数を使用して、文章の重複を取り除いている\n",
        "    new = set(new)\n",
        "\n",
        "    #set関数を使用しているので、元のリストと文章の順序が異なっている。\n",
        "    #文章の順序についてはこの時点で修正したほうが良さそう\n",
        "    sentence=\"\".join(new)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    word_list = get_morpheme(\"inputText.txt\")\n",
        "\n",
        "    #print(\"ワードリスト:{}\".format(word_list))\n",
        "    #print()\n",
        "\n",
        "    create_markov(word_list)\n",
        "\n",
        "    while(not sentence):\n",
        "        generate(word_list)\n",
        "        overlap()\n",
        "\n",
        "    print(\"【文章】\",sentence)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-514311d2a03e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mword_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_morpheme\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inputText.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m#print(\"ワードリスト:{}\".format(word_list))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-514311d2a03e>\u001b[0m in \u001b[0;36mget_morpheme\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mwordlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-514311d2a03e>\u001b[0m in \u001b[0;36mparse\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/janome/tokenizer.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, stream, wakati, baseform_unk, dotfile)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tokenize_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwakati\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseform_unk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdotfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tokenize_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwakati\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseform_unk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__tokenize_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwakati\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseform_unk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdotfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/janome/tokenizer.py\u001b[0m in \u001b[0;36m__tokenize_stream\u001b[0;34m(self, text, wakati, baseform_unk, dotfile)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mprocessed\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtext_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tokenize_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwakati\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseform_unk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdotfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/janome/tokenizer.py\u001b[0m in \u001b[0;36m__tokenize_partial\u001b[0;34m(self, text, wakati, baseform_unk, dotfile)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msys_dic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_partial_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                 \u001b[0mlattice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSurfaceNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNodeType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYS_DICT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m             \u001b[0mmatched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/janome/lattice.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mmin_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_left_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_cost\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mdic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0menode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0menode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_cost\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trans_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_left_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_cost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}